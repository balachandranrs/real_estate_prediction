{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (142) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "london = pandas.read_csv(\"/home/vivek/Documents/mydata/iimb/regression/regression_input_post_code_year_month_aggregate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2189743, 152)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummifying Month And Cluster Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "london[\"month\"] = london[\"year_month_new\"].map(lambda x:int(str(x)[4:]))\n",
    "monthDummies = pandas.get_dummies(london[\"month\"],prefix=\"month\"+\"_\")\n",
    "london = pandas.concat([london,monthDummies],axis=1)\n",
    "london.drop([\"month\"],axis=1,inplace=True)\n",
    "\n",
    "clusterDummies = pandas.get_dummies(london[\"cluster\"],prefix=\"cluster\"+\"_\")\n",
    "london = pandas.concat([london,clusterDummies],axis=1)\n",
    "london.drop([\"cluster\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "londonPrice = london[london[\"year_month_new\"]>=200901]  ## 199501 for full data\n",
    "dropList = [\"borough\",\"ward\",\"borough_code\",\"latitude\",\"longitude\",\"yearBetween\",\\\n",
    "            \"YearMon\",\"Year\",\"Month\",\"ward_code\",'avg_co2_emission_in_kt', 'avg_population']\n",
    "londonPrice = londonPrice.drop(dropList,axis=1)\n",
    "\n",
    "train = londonPrice[londonPrice[\"year_month_new\"]<201401]\n",
    "test = londonPrice[londonPrice[\"year_month_new\"]>=201401]\n",
    "testCols = train.columns[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1 460414963222.7638  1273784234.9982            5.34m\n",
      "         2 456097446626.0076  2433710850.0869            5.32m\n",
      "         3 457936795388.9999  1557800783.4706            5.45m\n",
      "         4 447452330129.0650  1303070696.7836            5.71m\n",
      "         5 448044461274.0524  1723526408.5315            5.80m\n",
      "         6 446093940704.8941  2599989996.2524            5.85m\n",
      "         7 445896995372.6137  2023894056.6814            5.76m\n",
      "         8 458094946294.9720  1321723778.7716            5.72m\n",
      "         9 451081879401.4693  2056799323.2302            5.69m\n",
      "        10 453678256383.8464  1082699920.0403            5.89m\n",
      "        20 438692538455.5643  1460114491.4177            5.37m\n",
      "        30 419359619252.9931  1230160538.5576            5.27m\n",
      "        40 388549247143.2611  1082968635.5794            5.14m\n",
      "        50 408094363296.7012  1355530732.3416            5.09m\n",
      "        60 370637830674.5212  1931763012.4727            5.20m\n",
      "        70 353718197845.6953   756819038.5601            5.21m\n",
      "        80 365015637426.9576  1168357657.7250            5.14m\n",
      "        90 327350394587.2069   842925114.0944            5.18m\n",
      "       100 348742533712.8799   409282434.9722            5.19m\n",
      "       200 287868469415.3222   207962616.8022            5.06m\n",
      "       300 272760028073.8426   292778172.5732            4.96m\n",
      "       400 255911535520.6436    48936971.1690            4.77m\n",
      "       500 238415217699.5305    68396854.0476            4.62m\n",
      "       600 217746622850.4628    40331735.7770            4.40m\n",
      "       700 234123577170.3645    51002533.6052            4.21m\n",
      "       800 228759503056.2516    17310049.1680            3.99m\n",
      "       900 229003741942.9611     8802855.0697            3.80m\n",
      "      1000 229347806458.2194    11520494.1296            3.60m\n",
      "      2000 209112809222.4867    -8958764.8874            1.79m\n",
      "      3000 196263748874.9095     -511425.9385            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1 148048933593.1328   310642858.0287            5.30m\n",
      "         2 136453599460.7408   610530264.0751            5.10m\n",
      "         3 143203333545.4403   427089788.6674            5.17m\n",
      "         4 140186275917.9929   238899631.9938            5.19m\n",
      "         5 140811619083.9712   617052468.8236            5.24m\n",
      "         6 144321697939.5448   672859188.5047            5.40m\n",
      "         7 135571088881.9770   669000500.2588            5.42m\n",
      "         8 137485964898.2908   906040513.3509            5.43m\n",
      "         9 137942635110.9073   365833996.9171            5.38m\n",
      "        10 135998043947.2852   196774953.4703            5.34m\n",
      "        20 132421183410.0968   319761482.4223            5.30m\n",
      "        30 125690081658.7876   450803018.1640            5.22m\n",
      "        40 126023970670.3952   196464008.0455            5.17m\n",
      "        50 119997444290.4868   403786532.2468            5.13m\n",
      "        60 115928380720.6689   489240264.5518            5.15m\n",
      "        70 117144327925.6585   339662726.1549            5.13m\n",
      "        80 115343016001.4287   219079700.1632            5.11m\n",
      "        90 111334163221.6256   171149957.0862            5.09m\n",
      "       100 110448137505.2816   341327847.1054            5.09m\n",
      "       200 90651661107.7120   119243523.8254            4.93m\n",
      "       300 78033643425.1358    33767633.6371            4.75m\n",
      "       400 76985330550.0968    22517632.6346            4.62m\n",
      "       500 69402670090.5042    42572215.2253            4.43m\n",
      "       600 69122131609.4904     6752423.9066            4.26m\n",
      "       700 66570149860.3241    13917778.6376            4.08m\n",
      "       800 62103032806.9971    18846190.2541            3.90m\n",
      "       900 62809214143.8315    16584398.4289            3.72m\n",
      "      1000 58921112806.1755     6910190.3592            3.54m\n",
      "      2000 59857219468.3810     1539179.0668            1.81m\n",
      "      3000 56454128353.6454     -396001.4195            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1 305348226712.9133  1016320758.7831           10.23m\n",
      "         2 303206825169.3019   707048440.0245           10.78m\n",
      "         3 308182409193.5550   764580188.9388           10.89m\n",
      "         4 299177698516.8224  1997623515.9596           10.98m\n",
      "         5 300901289662.1464  1629982255.3445           11.37m\n",
      "         6 295113762788.3132  1093147144.3483           11.62m\n",
      "         7 297891617957.1539  1821176777.0005           11.52m\n",
      "         8 299010501673.6884   770649347.6628           11.41m\n",
      "         9 282111300115.5718   866464103.2047           11.34m\n",
      "        10 292873756395.9828   737936315.2880           11.27m\n",
      "        20 272489591569.9142  1071061539.7853           11.33m\n",
      "        30 274290077160.5612  1190213127.4053           11.18m\n",
      "        40 263860794177.5254   805237357.2040           11.19m\n",
      "        50 251704506483.8872   489535098.0349           11.22m\n",
      "        60 249926858700.2300   870356730.6828           11.25m\n",
      "        70 247625821526.7001   383034471.6112           11.25m\n",
      "        80 243629212516.3736   880519785.4588           11.28m\n",
      "        90 240818313004.0282   447664270.0885           11.29m\n",
      "       100 224395072729.1904   322241601.9674           11.32m\n",
      "       200 202823052125.2600   132191591.8549           11.06m\n",
      "       300 181018790536.4347   114437345.3067           10.99m\n",
      "       400 171045761790.1223    63520459.5303           10.71m\n",
      "       500 168355355474.6374    41695960.3936           10.35m\n",
      "       600 161044299297.9115    23495509.1156            9.90m\n",
      "       700 159120864937.8621     8682032.7991            9.46m\n",
      "       800 156132902154.3942    24149096.4175            9.07m\n",
      "       900 156294708870.7972    19189324.2405            8.66m\n",
      "      1000 150434476723.3558     5996832.4388            8.22m\n",
      "      2000 140956355835.7990       59169.2484            3.99m\n",
      "      3000 136597908192.7592     1101310.6153            0.00s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gbm = GradientBoostingRegressor()\n",
    "param_grid = { \n",
    "    'n_estimators': [3000],\n",
    "    'max_features': [\"sqrt\"],\n",
    "    'min_samples_leaf':[5],\n",
    "    'min_samples_split':[5],\n",
    "#     'max_depth' : [15],\n",
    "    'subsample': [0.8],\n",
    "    'learning_rate':[0.01],\n",
    "    'criterion':[\"mse\"],\n",
    "    'verbose':[1]\n",
    "}\n",
    "grid_gbm = GridSearchCV(estimator=gbm, param_grid=param_grid, cv= 2)\n",
    "X_train = train[testCols]\n",
    "y = train[\"price\"]\n",
    "grid_gbm.fit(X_train,y)\n",
    "\n",
    "# Make predictions\n",
    "predsTrain =grid_gbm.predict(X= train[testCols])\n",
    "predsTest = grid_gbm.predict(X= test[testCols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Train And Test MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'mse', 'learning_rate': 0.01, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 3000, 'subsample': 0.8, 'verbose': 1}\n",
      "Train Mape:  0.2658982737908239\n",
      "Test Mape:  0.2769334513925649\n"
     ]
    }
   ],
   "source": [
    "print (grid_gbm.best_params_)\n",
    "trainResults = train\n",
    "trainResults[\"Predicted\"] = predsTrain\n",
    "postalMeanTrain = pandas.DataFrame(trainResults.groupby([\"post_code\"])[\"price\",\"Predicted\"].mean()).reset_index()\n",
    "postalMeanTrain[\"AP\"] = abs(postalMeanTrain[\"price\"]  -  postalMeanTrain[\"Predicted\"])/postalMeanTrain[\"price\"]\n",
    "print(\"Train Mape: \",postalMeanTrain.AP.mean())\n",
    "\n",
    "testResults = test\n",
    "testResults[\"Predicted\"] = predsTest\n",
    "postalMeanTest = pandas.DataFrame(testResults.groupby([\"post_code\"])[\"price\",\"Predicted\"].mean()).reset_index()\n",
    "postalMeanTest[\"AP\"] = abs(postalMeanTest[\"price\"]  -  postalMeanTest[\"Predicted\"])/postalMeanTest[\"price\"]\n",
    "print(\"Test Mape: \",postalMeanTest.AP.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Gradient Boost For Individual Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for clusNum in list(london[\"cluster\"].unique()):\n",
    "    print(\"cluster Num: \",clusNum)\n",
    "    londonPrice = london[london[\"cluster\"]==int(clusNum)]\n",
    "\n",
    "    londonPrice = londonPrice[londonPrice[\"year_month_new\"]>=200901] #199501 for full data\n",
    "    dropList = [\"borough\",\"ward\",\"borough_code\",\"latitude\",\"longitude\",\"yearBetween\",\\\n",
    "                \"YearMon\",\"Year\",\"Month\",\"ward_code\",'avg_co2_emission_in_kt', 'avg_population']\n",
    "    londonPrice = londonPrice.drop(dropList,axis=1)\n",
    "\n",
    "    train = londonPrice[londonPrice[\"year_month_new\"]<201401]\n",
    "    test = londonPrice[londonPrice[\"year_month_new\"]>=201401]\n",
    "    testCols = train.columns[3:]\n",
    "\n",
    "    X_train = train[testCols]\n",
    "    y = train[\"price\"]\n",
    "\n",
    "    # Initialize logistic regression model\n",
    "    gbm = GradientBoostingRegressor(n_estimators=5000,learning_rate=0.01,subsample=0.8,\\\n",
    "                                    max_features=\"sqrt\",min_samples_split=5)\n",
    "    # Train the model\n",
    "    gbm.fit(X = X_train,y = y)\n",
    "\n",
    "    # Make predictions\n",
    "    predsTrain =gbm.predict(X= train[testCols])\n",
    "    predsTest = gbm.predict(X= test[testCols])\n",
    "\n",
    "\n",
    "    trainResults = train\n",
    "    trainResults[\"Predicted\"] = predsTrain\n",
    "    postalMeanTrain = pandas.DataFrame(trainResults.groupby([\"post_code\"])[\"price\",\"Predicted\"].mean()).reset_index()\n",
    "    postalMeanTrain[\"AP\"] = abs(postalMeanTrain[\"price\"]  -  postalMeanTrain[\"Predicted\"])/postalMeanTrain[\"price\"]\n",
    "    print(\"Train Mape: \",postalMeanTrain.AP.mean())\n",
    "\n",
    "    testResults = test\n",
    "    testResults[\"Predicted\"] = predsTest\n",
    "    postalMeanTest = pandas.DataFrame(testResults.groupby([\"post_code\"])[\"price\",\"Predicted\"].mean()).reset_index()\n",
    "    postalMeanTest[\"AP\"] = abs(postalMeanTest[\"price\"]  -  postalMeanTest[\"Predicted\"])/postalMeanTest[\"price\"]\n",
    "    print(\"Test Mape: \",postalMeanTest.AP.mean())\n",
    "\n",
    "    print (\"R2\",gbm.score(X = X_train,y = y))\n",
    "    print(\"######## End Of Iteration ######\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
